{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c855e-3888-4a83-8151-b2d1ad488f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter, defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c1d1f-2849-4c9c-9205-b242e8a5729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"finalds8.csv\",encoding=\"utf-8\", delimiter=\",\")\n",
    "test = pd.read_csv(\"traineddata8.csv\",encoding=\"utf-8\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c97bda-afff-4a01-8711-b9951f71b919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339f733-41ab-4fda-a8be-8c78ae0a860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sns.countplot(x='Sentiments', data=train)\n",
    "f.set_title(\"Sentiment distribution on Environmental news from different TV Networks\")\n",
    "f.set_xticklabels(['Positive', 'Negative'])\n",
    "plt.xlabel(\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a7171-f78b-4fb1-8a91-7cf19ee24680",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(review for review in train.review)\n",
    "\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\", stopwords=stopwords.words(\"english\")).generate(text)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7831e72-6cc5-475c-af09-9150481622c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "  \n",
    "  def clean(self, text):\n",
    "      no_html = BeautifulSoup(text).get_text()\n",
    "      clean = re.sub(\"[^a-z\\s]+\", \" \", no_html, flags=re.IGNORECASE)\n",
    "      return re.sub(\"(\\s+)\", \" \", clean)\n",
    "\n",
    " \n",
    "  def tokenize(self, text):\n",
    "      clean = self.clean(text).lower()\n",
    "      stopwords_en = stopwords.words(\"english\")\n",
    "      return [w for w in re.split(\"\\W+\", clean) if not w in stopwords_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c1c05-9d2c-4af1-841b-3b5e069bbb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayes:\n",
    "  \n",
    "    def __init__(self, classes, tokenizer):\n",
    "      self.tokenizer = tokenizer\n",
    "      self.classes = classes\n",
    "      \n",
    "    def group_by_class(self, X, y):\n",
    "      data = dict()\n",
    "      for c in self.classes:\n",
    "        data[c] = X[np.where(y == c)]\n",
    "      return data\n",
    "           \n",
    "    def fit(self, X, y):\n",
    "        self.n_class_items = {}\n",
    "        self.log_class_priors = {}\n",
    "        self.word_counts = {}\n",
    "        self.vocab = set()\n",
    "\n",
    "        n = len(X)\n",
    "        \n",
    "        grouped_data = self.group_by_class(X, y)\n",
    "        \n",
    "        for c, data in grouped_data.items():\n",
    "          self.n_class_items[c] = len(data)\n",
    "          self.log_class_priors[c] = math.log(self.n_class_items[c] / n)\n",
    "          self.word_counts[c] = defaultdict(lambda: 0)\n",
    "          \n",
    "          for text in data:\n",
    "            counts = Counter(self.tokenizer.tokenize(text))\n",
    "            for word, count in counts.items():\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab.add(word)\n",
    "\n",
    "                self.word_counts[c][word] += count\n",
    "                \n",
    "        return self\n",
    "      \n",
    "    def laplace_smoothing(self, word, text_class):\n",
    "      num = self.word_counts[text_class][word] + 1\n",
    "      denom = self.n_class_items[text_class] + len(self.vocab)\n",
    "      return math.log(num / denom)\n",
    "      \n",
    "    def predict(self, X):\n",
    "        result = []\n",
    "        for text in X:\n",
    "          \n",
    "          class_scores = {c: self.log_class_priors[c] for c in self.classes}\n",
    "\n",
    "          words = set(self.tokenizer.tokenize(text))\n",
    "          for word in words:\n",
    "              if word not in self.vocab: continue\n",
    "\n",
    "              for c in self.classes:\n",
    "                \n",
    "                log_w_given_c = self.laplace_smoothing(word, c)\n",
    "                class_scores[c] += log_w_given_c\n",
    "                \n",
    "          result.append(max(class_scores, key=class_scores.get))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830f141-88d8-4a9f-9ab1-56ff31cdfbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['review'].values\n",
    "y = train['Sentiments'].values\n",
    "  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ff56a5-7e2f-4f2d-999c-500a597885a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNB = MultinomialNaiveBayes(\n",
    "    classes=np.unique(y), \n",
    "    tokenizer=Tokenizer()\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41026bf7-0f43-4145-9d15-177a58042def",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = MNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb1673-7c9c-456b-ae69-ea1dedece9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6faee-8a14-4e1c-9076-b25deab2c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f822d23-1252-4d4c-8a79-c94675232106",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_hat)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c879d8-f30e-4dbd-b265-df09bdd83669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"negative\", \"positive\"]\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False, xticklabels=class_names, yticklabels=class_names)\n",
    "ax.xaxis.set_label_position('top')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Actual sentiment')\n",
    "plt.xlabel('Predicted sentiment');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04330771-082b-4dc9-a8b0-cd175741c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12043b31-aa3b-409c-9ebf-a1f169768471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
